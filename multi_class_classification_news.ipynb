{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52244b37",
   "metadata": {},
   "source": [
    "This code was used in \"Predict The News Category Hackathon\" ( https://machinehack.com/hackathon/predict_the_news_category_hackathon/overview) and resulted in public score of 0.9829 - 0.0094 behind the winning submission (rank 53 as of 15.01.2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370126f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e5deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_model import build_model\n",
    "from preprocessing import create_tokenizer_from_hub_module, convert_single_example, \\\n",
    "                        convert_examples_to_features, convert_text_to_examples, initialize_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c6f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_functions import plot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab6254",
   "metadata": {},
   "source": [
    "Let's load the data and see what our columns look like.\n",
    "Note that there is one column with prediction target and it is non-binary. This means that we are dealing with multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ada2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the most painful was the huge reversal in ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable is the opposition alliance amon...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currencies were trading lower today...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want to answer any question, click on ‘...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global markets, gold prices edged up today ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION\n",
       "0  But the most painful was the huge reversal in ...      3.0\n",
       "1  How formidable is the opposition alliance amon...      0.0\n",
       "2  Most Asian currencies were trading lower today...      3.0\n",
       "3  If you want to answer any question, click on ‘...      1.0\n",
       "4  In global markets, gold prices edged up today ...      3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r'Data_Train.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4925d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7628, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62287241",
   "metadata": {},
   "source": [
    "Using 0.1 as dev size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f7f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b8e32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6865, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada72718",
   "metadata": {},
   "source": [
    "Check the average length of a news story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437a5e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.65506190823015"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(t.split()) for t in train['STORY'].tolist()]\n",
    "sum(lens) / len(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d991eed",
   "metadata": {},
   "source": [
    "100 seems to be a reasonable choice of max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4660f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e54522",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['STORY'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "dev_text = dev['STORY'].tolist()\n",
    "dev_text = np.array(dev_text, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ac0d149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5760054",
   "metadata": {},
   "source": [
    "Convert data to InputExample format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25f6d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = convert_text_to_examples(train_text)\n",
    "dev_examples = convert_text_to_examples(dev_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ce342",
   "metadata": {},
   "source": [
    "Convert data to BERT input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc96f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6865/6865 [00:20<00:00, 334.01it/s]\n",
      "Converting examples to features: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 763/763 [00:02<00:00, 341.35it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_input_ids,\n",
    "train_input_masks,\n",
    "train_segment_ids) = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "(dev_input_ids,\n",
    "dev_input_masks,\n",
    "dev_segment_ids) = convert_examples_to_features(tokenizer, dev_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "358cdabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6865, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ca5b0",
   "metadata": {},
   "source": [
    "Get the column with labels.\n",
    "Get the number of unique labels - will need it to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b026ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(set(train['SECTION'].tolist()))\n",
    "train_labels = train['SECTION'].to_numpy()\n",
    "dev_labels = dev['SECTION'].to_numpy()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57ee61",
   "metadata": {},
   "source": [
    "EarlyStopping in case val_loss does not go down over 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0d2d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                min_delta=0,\n",
    "                                patience=3,\n",
    "                                verbose=0,\n",
    "                                mode='auto',\n",
    "                                baseline=None,\n",
    "                                restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a8d94",
   "metadata": {},
   "source": [
    "Building the model: passing max_seq_length to define the input shape, and num_labels to define the number of units in the last layer.\n",
    "Compiling the model: for multi-class classifiction where each label is a number, we use sparse_categorical_crossentropy loss and accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(max_seq_length, num_labels)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate = 5e-5, beta_1=0.8),\n",
    "                 metrics=[\"accuracy\"])model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3545ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4975ffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6865 samples, validate on 763 samples\n",
      "Epoch 1/20\n",
      "6865/6865 [==============================] - 1461s 213ms/sample - loss: 0.1480 - acc: 0.9511 - val_loss: 0.0714 - val_acc: 0.9751\n",
      "Epoch 2/20\n",
      "6865/6865 [==============================] - 1461s 213ms/sample - loss: 0.0470 - acc: 0.9849 - val_loss: 0.0599 - val_acc: 0.9790\n",
      "Epoch 3/20\n",
      "6865/6865 [==============================] - 1463s 213ms/sample - loss: 0.0216 - acc: 0.9926 - val_loss: 0.0525 - val_acc: 0.9830\n",
      "Epoch 4/20\n",
      "6865/6865 [==============================] - 1425s 208ms/sample - loss: 0.0118 - acc: 0.9956 - val_loss: 0.0629 - val_acc: 0.9790\n",
      "Epoch 5/20\n",
      "6865/6865 [==============================] - 1419s 207ms/sample - loss: 0.0080 - acc: 0.9964 - val_loss: 0.1230 - val_acc: 0.9712\n",
      "Epoch 6/20\n",
      "6865/6865 [==============================] - 1471s 214ms/sample - loss: 0.0138 - acc: 0.9943 - val_loss: 0.0380 - val_acc: 0.9882\n",
      "Epoch 7/20\n",
      "6865/6865 [==============================] - 1478s 215ms/sample - loss: 0.0073 - acc: 0.9964 - val_loss: 0.0240 - val_acc: 0.9934\n",
      "Epoch 8/20\n",
      "6865/6865 [==============================] - 1471s 214ms/sample - loss: 0.0052 - acc: 0.9974 - val_loss: 0.0318 - val_acc: 0.9908\n",
      "Epoch 9/20\n",
      "6865/6865 [==============================] - 1281s 187ms/sample - loss: 0.0050 - acc: 0.9971 - val_loss: 0.0281 - val_acc: 0.9882\n",
      "Epoch 10/20\n",
      "6865/6865 [==============================] - 1266s 184ms/sample - loss: 0.0048 - acc: 0.9975 - val_loss: 0.0287 - val_acc: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25843548c08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids],\n",
    "    train_labels,\n",
    "    validation_data=(\n",
    "        [dev_input_ids, dev_input_masks, dev_segment_ids],\n",
    "        dev_labels,\n",
    "    ),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[my_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1484e2",
   "metadata": {},
   "source": [
    "Plot model history for accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label(history, 'acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ac18f",
   "metadata": {},
   "source": [
    "Plot model history for loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f5a7b",
   "metadata": {},
   "source": [
    "To save the model's weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb978a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(r'weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8aa50f",
   "metadata": {},
   "source": [
    " Load test data and convert to BERT input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dd3ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(r'Data_Test.xlsx')\n",
    "test_text = test['STORY'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a650bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = convert_text_to_examples(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57a8fcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2748/2748 [00:07<00:00, 349.45it/s]\n"
     ]
    }
   ],
   "source": [
    "(test_input_ids,\n",
    "test_input_masks,\n",
    "test_segment_ids) = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe48a4a",
   "metadata": {},
   "source": [
    "Let's predict test data labels now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "209ac474",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([test_input_ids,\n",
    "    test_input_masks,\n",
    "    test_segment_ids], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95567f8d",
   "metadata": {},
   "source": [
    "Convert probabilities to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3568cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "To save predictions as a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c0c835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_class, columns=['SECTION'])\n",
    "results.to_csv(r'predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc5e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
