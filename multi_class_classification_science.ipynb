{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae474c70",
   "metadata": {},
   "source": [
    "This code was used in \"Science nlp classification\" challenge (https://www.kaggle.com/c/nlpsci/leaderboard#score) and resulted in the score of 0.81720 - 1st place as of 15.01.2022!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370126f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e5deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_model import build_model\n",
    "from preprocessing import create_tokenizer_from_hub_module, convert_single_example, \\\n",
    "                        convert_examples_to_features, convert_text_to_examples, initialize_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_functions import plot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e85c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd87f8",
   "metadata": {},
   "source": [
    "Let's load the data and see what our columns look like.\n",
    "Note that there is one column with prediction target and it is non-binary. This means that we are dealing with multi-class classification.\n",
    "Also note that there are two columns with input text: TITLE and ABSTRACT. In this approach, I simply merged them into one input text. An alternative approach will be shown in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74ada2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Anna\\Files\\mylearning\\ScienceCategories\\nlpsci\\train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baaffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['TITLE'] + ' ' + data['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4925d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15972, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa8f79",
   "metadata": {},
   "source": [
    "Using 0.1 as dev set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f7f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79b8e32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14374, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fee32",
   "metadata": {},
   "source": [
    "Check the average length of an input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "437a5e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.32711840823708"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(t.split()) for t in train['text'].tolist()]\n",
    "sum(lens) / len(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3098382",
   "metadata": {},
   "source": [
    "150 looks like a reasonable choice of max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4660f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15e54522",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['text'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "dev_text = dev['text'].tolist()\n",
    "dev_text = np.array(dev_text, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ac0d149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6a82c",
   "metadata": {},
   "source": [
    "Convert data to InputExample format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25f6d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = convert_text_to_examples(train_text)\n",
    "dev_examples = convert_text_to_examples(dev_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a57dbe",
   "metadata": {},
   "source": [
    "Convert data to BERT input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc96f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14374/14374 [01:37<00:00, 147.90it/s]\n",
      "Converting examples to features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1598/1598 [00:11<00:00, 145.08it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_input_ids,\n",
    "train_input_masks,\n",
    "train_segment_ids) = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "(dev_input_ids,\n",
    "dev_input_masks,\n",
    "dev_segment_ids) = convert_examples_to_features(tokenizer, dev_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "358cdabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14374, 150)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64d414",
   "metadata": {},
   "source": [
    "Get the column with labels.\n",
    "Get the number of unique labels - will need it to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed068591",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(set(train['label'].tolist()))\n",
    "train_labels = train['label'].to_numpy()\n",
    "dev_labels = dev['label'].to_numpy()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993ecf7",
   "metadata": {},
   "source": [
    "EarlyStopping in case val_loss does not go down over 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d2d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                min_delta=0,\n",
    "                                patience=3,\n",
    "                                verbose=0,\n",
    "                                mode='auto',\n",
    "                                baseline=None,\n",
    "                                restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bd1cc",
   "metadata": {},
   "source": [
    "Building the model: passing max_seq_length to define the input shape, and num_labels to define the number of units in the last layer.\n",
    "Compiling the model: for multi-class classifiction where each label is a number, we use sparse_categorical_crossentropy loss and accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08743278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(max_seq_length, num_labels)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate = 5e-5, beta_1=0.8),\n",
    "                 metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2259829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:2: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:2: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:3: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:3: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:4: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:4: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:5: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_9116/3640279717.py:5: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate variables\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4975ffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anna\\pycharmprojects\\ugam_sentiment\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14374 samples, validate on 1598 samples\n",
      "Epoch 1/20\n",
      "14374/14374 [==============================] - 4624s 322ms/sample - loss: 0.5874 - acc: 0.7868 - val_loss: 0.5577 - val_acc: 0.7910\n",
      "Epoch 2/20\n",
      "14374/14374 [==============================] - 4556s 317ms/sample - loss: 0.4617 - acc: 0.8270 - val_loss: 0.5392 - val_acc: 0.7997\n",
      "Epoch 3/20\n",
      "14374/14374 [==============================] - 4574s 318ms/sample - loss: 0.3837 - acc: 0.8495 - val_loss: 0.5682 - val_acc: 0.7966\n",
      "Epoch 4/20\n",
      "14374/14374 [==============================] - 4562s 317ms/sample - loss: 0.2798 - acc: 0.8853 - val_loss: 0.6534 - val_acc: 0.7860\n",
      "Epoch 5/20\n",
      "14374/14374 [==============================] - 4559s 317ms/sample - loss: 0.1720 - acc: 0.9283 - val_loss: 0.7305 - val_acc: 0.7947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e61fd05fc8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids],\n",
    "    train_labels,\n",
    "    validation_data=(\n",
    "        [dev_input_ids, dev_input_masks, dev_segment_ids],\n",
    "        dev_labels,\n",
    "    ),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[my_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8eea4",
   "metadata": {},
   "source": [
    "Plot model history for accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label(history, 'acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb60263",
   "metadata": {},
   "source": [
    "Plot model history for loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aac4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c9bb5",
   "metadata": {},
   "source": [
    "To save the model's weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96774235",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(r'weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e36da",
   "metadata": {},
   "source": [
    " Load test data and convert to BERT input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dd3ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r'C:\\Users\\Anna\\Files\\mylearning\\ScienceCategories\\nlpsci\\test.csv')\n",
    "test['text'] = test['TITLE'] + ' ' + test['ABSTRACT']\n",
    "test_text = test['text'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a650bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = convert_text_to_examples(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57a8fcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:35<00:00, 141.68it/s]\n"
     ]
    }
   ],
   "source": [
    "(test_input_ids,\n",
    "test_input_masks,\n",
    "test_segment_ids) = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2936d479",
   "metadata": {},
   "source": [
    "Let's predict test data labels now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "209ac474",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([test_input_ids,\n",
    "                        test_input_masks,\n",
    "                        test_segment_ids], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d201649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50506a65",
   "metadata": {},
   "source": [
    "Convert probabilities to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5987a4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 3, 2, 3, 2, 2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = np.argmax(pred, axis = 1)\n",
    "pred_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69a299e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93abe4bb",
   "metadata": {},
   "source": [
    "Add the needed columns names for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c0c835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=pred_class, columns=['label'])\n",
    "results['ID'] = results.index + 1\n",
    "columns_titles = [\"ID\",\"label\"]\n",
    "results=results.reindex(columns=columns_titles)\n",
    "results.to_csv(r'submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc5e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
